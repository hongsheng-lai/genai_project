Robust H‚àûcontrol and worst-case search in constrained parametric space
Ervan Kassarian1, Francesco Sanfedino2, Daniel Alazard2, Andrea Marrazza1
Abstract
Standard H‚àû/H2 robust control and analysis tools operate on uncertain parameters assumed to vary independently within
prescribed bounds. This paper extends their capabilities in the presence of constraints coupling these parameters and restricting
the parametric space. Focusing on the worst-case search, we demonstrate ‚Äì based on the theory of upper-C1 functions ‚Äì the
validity of using standard, readily available smooth optimization algorithms to address this nonsmooth constrained optimization
problem. Accordingly, we propose to explore the parametric space with either Monte-Carlo sampling or particle swarm
optimization, and to subsequently perform local exploitation with Sequential Quadratic Programming to compute Karush-
Kuhn-Tucker points. This worst-case search then enables robust controller synthesis: as in the state-of-art algorithm for
standard robust control, identiÔ¨Åed worst-case conÔ¨Ågurations are iteratively added to an active set on which a non-smooth
multi-models optimization of the controller is performed. The methodology is illustrated on a satellite benchmark with Ô¨Çexible
appendages, of order 50 with 43 uncertain parameters. We show that the proposed method largely outperforms Monte-Carlo
sampling alone, is able to reliably detect even rare worst-case conÔ¨Ågurations in minutes on a standard laptop, and that the
robust controller optimization converges with less than 10 active conÔ¨Ågurations. Even in the unconstrained case, the proposed
framework complements traditional methods, as it scales to plants with many parameters and states and explores the entire
parametric space, albeit without formal guarantees of global optimality.
I. INTRODUCTION
The standard robust structured H‚àûcontrol problem [1] is formulated as the min-max optimization problem:
minimize
K‚ààK
max
Œ¥‚ààD ||Tzw(s, K, Œ¥)||‚àû
(1)
where Tzw(s, K, Œ¥) is a transfer function between input w and output z, K is the controller to be optimized, K is the set of
controllers of the chosen structure, and Œ¥ is the vector of k uncertain parameters in a parametric space D. A multi-objective
formulation can also be stated as follows:
minimize
K‚ààK
max
Œ¥‚ààD ||Tz1w1(s, K, Œ¥)||
subject to
max
Œ¥‚ààD ||Tziwi(s, K, Œ¥)|| ‚â§1 , 2 ‚â§i ‚â§n
(2)
where || ¬∑ || may refer to the H2 or H‚àûsystem norm. The channel w1 ‚Üíz1 corresponds to a ‚Äùsoft‚Äù requirement to be
minimized, while the other channels wi ‚Üízi (i > 1) are ‚Äùhard‚Äù requirements, that must be inferior to 1 (once normalized)
but not necessarily minimized.
In this paper, we mainly focus on the inner maximization problems, namely search for worst-case performance:
max
Œ¥‚ààD ||Tzw(s, K, Œ¥)||
(3)
and worst-case stability ‚Äì stability is implicitly required to ensure Ô¨Ånite norms ‚Äì treated as in [2]:
max
Œ¥‚ààD Œ±(A(K, Œ¥))
(4)
where A(K, Œ¥) is the matrix A of the state-space representation of the closed-loop system, and Œ±(¬∑) denotes the spectral
abscissa:
Œ±(M) := max{Re(Œª) : Œª is an eigenvalue of M} .
Classically in the literature, D is the hypercube [‚àí1, 1]k after normalization of the uncertain parameters, and Tzw(s, K, Œ¥)
is modeled under the Linear Fractional Representation (LFR). In this case, the function SYSTUNE of MATLAB‚Äôs Robust
Control Toolbox, relying on the non-smooth optimization of [2], [3], is now widely used in academia and industry to solve
problems (1) and (2). More speciÔ¨Åcally, in [2], problems (3) and (4) are solved with local non-smooth optimization. Indeed,
the computation of Clarke subdifferentials [4] of the spectral abscissa and of the H‚àûnorm [5] enables a bundle method to
quickly Ô¨Ånd worst-case conÔ¨Ågurations with regard to stability and performance. The control problem (1) is then tackled by
combining this worst-case search with the non-smooth controller optimization of [3]. This approach relies on the construction
of an inner approximation Da ‚äÇD composed of so-called active conÔ¨Ågurations. At each iteration, the controller is tuned so
as to be robust to all current active conÔ¨Ågurations. Then, a worst-case search is performed; if the worst-case conÔ¨Åguration
does not satisfy the control requirements, it is added to Da and the algorithm goes back to controller tuning; otherwise,
1DYCSYT, 10 Avenue Marc P¬¥elegrin, 31400 Toulouse, France.
2F¬¥ed¬¥eration ENAC ISAE-SUPAERO ONERA, Universit¬¥e de Toulouse, 10 Avenue Marc P¬¥elegrin, Toulouse, 31400, France
arXiv:2511.15480v1  [eess.SY]  19 Nov 2025


the algorithm can terminate. It is shown that this approach is both more reliable and more efÔ¨Åcient than gridding the
parametric space, which quickly becomes intractable when the number of parameters increases. In practice, the optimization
generally Ô¨Ånishes with a small number of active conÔ¨Ågurations. As this approach relies on local searches, robustness is
generally thoroughly veriÔ¨Åed a posteriori. ¬µ-analysis [6] was developed for this purpose, generally based on branch-and-
bound algorithms [7]. It provides guaranteed deterministic lower and upper bounds of the global optimum; a probabilistic
variant also exists [8], [9]. Monte-Carlo sampling can also guarantee a probability of robustness within predeÔ¨Åned thresholds
of accuracy and conÔ¨Ådence [10]. Another common industrial practice is to grid the parametric space with a limited number
of samples, typically 100 to 1000 combinations of the parameters bounds. But this approach will miss any worst case
occurring between grid points and, unlike Monte-Carlo, does not provide any statistical guarantee.
This paper addresses the case where nonlinear constraints, noted ci(Œ¥) ‚â§0 and possibly including equality constraints,
restrict the hypercube:
D = {Œ¥ ‚àà[‚àí1, 1]k s.t. ci(Œ¥) ‚â§0, 1 ‚â§i ‚â§n}
(5)
Our focus is twofold. Firstly, we seek computationally efÔ¨Åcient techniques that can be integrated into robust control design,
alternating between multi-models controller synthesis and worst-case search as in [2], to solve the standard problem (1) and
its multi-objectives formulation (2) in reasonable time. Secondly, we aim to assess their reliability in consistently detecting
global worst-case conÔ¨Ågurations as a validation tool.
The robust control and analysis approaches discussed above do not address the constrained case, at least not in their
current implementations. Nevertheless, quantifying robustness can still be approached with Monte-Carlo sampling; samples
that do not satisfy the nonlinear constraint are simply discarded. Evaluating the stability or the norm of a linear system at
a given parametric conÔ¨Åguration is relatively fast, and easily parallelizable; moreover, the number of evaluations required
to provide the desired levels of probability and conÔ¨Ådence is independent from the number of parameters [10]. However,
Ô¨Ånding a worst case, e.g. to address problems (3) or (4), may require numerous function evaluations and lead to a signiÔ¨Åcant
computation time, especially in critical systems for which even rare worst cases must be avoided. This is particularly an
issue when the robustness analysis iterates with controller design to perform robust tuning.
In this paper, we demonstrate new properties of the class of upper-C1 functions [11], and in particular the convergence
of Sequential Quadratic Programming (SQP) [12], a standard constrained optimization algorithm, when applied to such
functions even though they are not smooth. We deduce that SQP can be applied to the nonsmooth problem (3), and to (4)
under an additional assumption. Then, relying on built-in MATLAB functions, we propose to explore the parametric space
with either Particle Swarm Optimization (PSO) [13], tackling the nonlinear constraint through a penalty approach [14], or
Monte-Carlo sampling (if stochastic guarantees are sought), and subsequently reÔ¨Åne the search with SQP to Ô¨Ånd Karush-
Kuhn-Tucker points of the optimization problem. Then, following the approach of [2], this worst-case search method is then
combined with multi-models controller optimization [3] to perform robust control. To the best of our knowledge, this is the
Ô¨Årst robust H‚àûcontrol approach that tackles nonlinear constraints on the uncertain parameters.
We emphasize that the proposed techniques, although studied here in the context of the constrained space (5), may also
prove valuable in the unconstrained case. Indeed, ¬µ-analysis remains difÔ¨Åcult to apply to industrial systems with many
uncertain parameters ‚Äì as illustrated in the recent references [15], [16], [17], [18] where systems with 16 to 20 parameters
required sensitivity-based model reduction to make the problem tractable, at the expense of model Ô¨Ådelity. In particular,
[19] shows that such ¬µ-analysis can even lead to an overly optimistic worst-case prediction after model reduction. This
occurs because the formal robustness guarantees apply only to the reduced model and do not extend to the original system,
thus limiting the practical value of sensitivity-based ¬µ-analysis. By contrast, the proposed approach scales well to plants
with many states and parameters, and thus can be applied to the full system. Furthermore, the non-smooth optimization
of [2], implemented in SYSTUNE, is local and sometimes misses worst-case conÔ¨Ågurations, whereas the proposed approach
performs a global exploration of the parametric space, albeit without formal guarantees of global optimality.
We illustrate the proposed approach on the robust control of a spacecraft with Ô¨Çexible appendage. In such systems,
uncertainties associated with the mechanical properties of Ô¨Çexible appendages must satisfy a condition of the form (5) or
otherwise be excluded from robustness analysis (speciÔ¨Åcally, the residual mass matrix must remain positive deÔ¨Ånite). While
structured H‚àûcontrol has become industrial standard practice among satellite integrators for missions with demanding
control requirements [17], [20], [21], [22], this constraint, and more generally the robustness analysis, is generally handled
using Monte-Carlo or gridding approaches, which suffer from the aforementioned drawbacks. The proposed methodology
offers a practical and scalable alternative that can signiÔ¨Åcantly reduce engineering effort and computational cost.
II. CONSTRAINED OPTIMIZATION OF UPPER-C1 FUNCTIONS
A. Properties of upper-C1 functions
In this section, we introduce the class of upper-C1 functions and demonstrate favorable properties for their minimization.
This will be relevant for the robust control problem, which, as we shall see, involves such functions. For readability and


since our primary focus is on robust control, proofs that result from adapting existing arguments from the differentiable to
the upper-C1 functions are only provided in Appendix.
DeÔ¨Ånition 1 (Lower- and upper-C1 functions [11])
A locally Lipschitz function f : Rn ‚ÜíR is upper-C1 at x ‚ààRn if there exists a compact set S, a neighborhood U of x,
and a function F : U √ó S ‚ÜíR such that F and ‚àáxF are jointly continuous in x and s, and such that
f(x) = min
s‚ààS F(x‚Ä≤, s)
for all x‚Ä≤ ‚ààU.
We note I(x) the subset of S that deÔ¨Ånes the active functions F(¬∑, s) at x, i.e.:
I(x) = arg min
s‚ààS F(x, s) = {s ‚ààS, f(x) = F(x, s)} .
f is lower-C1 if ‚àíf is upper-C1, i.e. f can be written as a maximum, similarly to the expression above.
[2, Sections III.A., II.B., V.A.] shows that minimization of such upper-C1 functions, even when not differentiable
everywhere, exhibits similar behavior to smooth functions. In particular, the authors show the convergence of their bundle
method, in the search of the worst-case H‚àûnorm, even when the cutting plane step is reduced to a standard linesearch (as
in smooth optimization). This work follows [23] that treats of the optimization of lower- and upper-C1 functions. Similar
considerations are also thoroughly discussed by the same authors in [24]. Similarly, in [25], the Frank-Wolfe algorithm,
originally designed for smooth functions, is also proven to converge to Clarke-stationnary points when applied to upper-C1
functions. In the same spirit, we now show that the upper-C1 functions, although not differentiable everywhere, maintain
some favorable properties for their minimization. Then, we will demonstrate the convergence of one particular smooth
optimization algorithm when applied to upper-C1 functions.
In this whole Section, we consider f : Rk ‚ÜíR an upper-C1 function. Let us Ô¨Årst consider the unconstrained problem:
minimize
x‚ààRk
f(x)
(6)
Proposition 1 (Descent directions and optimality of upper-C1 functions ‚Äì Unconstrained case)
Let a locally Lipschitz function f be upper-C1 at x, and gx ‚àà‚àÇf(x) any subgradient of f at x. We consider Problem (6).
a) Descent direction. Any direction ‚àígx, with gx ‚àà‚àÇf(x) such that ||gx|| Ã∏= 0, is a descent direction for f(x), and in
particular it veriÔ¨Åes f ‚Ä≤(x, ‚àígx) ‚â§‚àí||gx||2 < 0 where f ‚Ä≤(x, d) denotes the the directional derivative at x in direction d.
b) Optimality. If x (locally) minimizes f(x), then ||gx|| = 0 for any gx ‚àà‚àÇf(x).
Proof. a) [25, Proposition 2 and equation (6)] shows that the directional derivative of an upper-C1 function f is:
f ‚Ä≤(x, d) =
min
g‚àà‚àÇf(x)‚ü®g, d‚ü©= min
u‚ààI(x)‚ü®‚àáxF(x, u), d‚ü©
(7)
where ‚ü®¬∑, ¬∑‚ü©denotes the scalar product. From equation (7), f ‚Ä≤(x, ‚àígx) = ming‚àà‚àÇf(x)(‚àígTgx) ‚â§‚àígT
x gx = ‚àí||gx||2 ‚â§0 and
the last inequality is strict when ||gx|| Ã∏= 0.
b) If x minimizes f, then f ‚Ä≤(x, ‚àígx) ‚â•0. But, by a), f ‚Ä≤(x, ‚àígx) ‚â§‚àí||gx||2. Thus, ||gx|| = 0.
Proposition 1.a) shows that when a smooth optimization algorithm is provided with any subgradient as if it were the
gradient of a smooth function, progress can still be achieved at points of nonsmoothness, owing to the regularity property of
upper-C1 functions. Naturally, the selected direction is not necessarily the steepest descent. Proposition 1.b) ensures that an
optimization algorithm can rely on the same optimality conditions as in the smooth case when picking any subgradient (we
recall that, for the general case of nonsmooth functions, the optimality condition is 0 ‚àà‚àÇf(x), which is a weaker condition).
We shall now demonstrate similar results for the constrained problem:
minimize
x‚ààRk
f(x)
subject to
ci(x) ‚â§0 , 1 ‚â§i ‚â§n
(8)
where the ci are differentiable, and f is upper-C1. We do not consider equality constraints, as they can be written equivalently
as two inequality constraints. The Karush-Kuhn-Tucker (KKT) conditions of Problem (8) read: there exists gx ‚àà‚àÇf(x) and
(ui)1‚â§i‚â§n such that:
gx + Pn
i=1 ui‚àáci(x) = 0
‚àÄi, ui ‚â•0, uici(x) = 0, ci(x) ‚â§0
(9)


We also consider the quadratic problem:
Q(x, H, gx) :
minimize
p‚ààRk
gT
x p + 1
2pT Hp
subject to
ci(x) + ‚àáci(x)T p ‚â§0 , 1 ‚â§i ‚â§n
(10)
where H is a symmetric deÔ¨Ånite positive matrix and gx ‚àà‚àÇf(x). The quadratic problem Q(x, H, gx) can be seen as a local
approximation of the Problem (8) where the matrix H may contain information about the curvature of both objective and
constraint functions, usually serving as an approximation of the Lagrangian. Q(x, H, gx) is originally introduced in methods
such as [26] where f is differentiable and ‚àáf(x) replaces gx.
Finally, for r ‚â•0, we introduce the merit function Œ∏r as in [26]:
Œ∏r(x) = f(x) + r
n
X
i=1
ci(x)+
(11)
where ci(x)+ = max(0, ci(x)).
Proposition 2 (Descent directions and optimality of upper-C1 functions ‚Äì Constrained case)
Let a locally Lipschitz function f be upper-C1 at x, and gx ‚àà‚àÇf(x) any subgradient of f at x. Let the ci be continuously
differentiable. We consider Problem (8).
a) Descent direction. Let (p, u) be a KKT pair of Q(x, H, gx). If ||p|| Ã∏= 0 and ||u||‚àû‚â§r, then p is a descent direction
for Œ∏r(x), i.e. Œ∏‚Ä≤
r(x, p) < 0 where Œ∏‚Ä≤
r(x, d) denotes the the directional derivative at x in direction d.
b) Optimality. If x (locally) minimizes f(x) subject to n constraints ci(x) ‚â§0 (Problem (8)), then any gx ‚àà‚àÇf(x) veriÔ¨Åes
the following KKT conditions: there exists (¬µi)1‚â§i‚â§n such that:
gx + Pn
i=1 ¬µi‚àáci(x) = 0
‚àÄi, ¬µi ‚â•0, ¬µici(x) = 0, ci(x) ‚â§0
Proof. a) Cf. Appendix. The proof is a mere adaptation of [26, Theorem 3.1] to the upper-C1 case.
b) Let us note C = {x, ci(x) ‚â§0 ‚àÄi}. Since x is a local minimizer of f(x) in C, there exists a ball B(x, r1) of radius r1 > 0
and of center x such that f(x‚Ä≤) ‚â•f(x) for all x‚Ä≤ ‚ààB(x, r1) ‚à©C. Recall that U is the neighborhood of x of DeÔ¨Ånition 1; as
B(x, r1) and U are both non-empty neighborhoods of x, we can deÔ¨Åne r2 > 0 such that B(x, r2) ‚äÇB(x, r1) ‚à©U. Let us
consider any of the functions F(¬∑, s). For all x‚Ä≤ ‚ààB(x, r2)‚à©C, we have F(x‚Ä≤, s) ‚â•f(x‚Ä≤) ‚â•f(x), where the Ô¨Årst inequality
follows from x‚Ä≤ ‚ààU, and the second from x‚Ä≤ ‚ààB(x, r1) ‚à©C. Assuming additionally that F(¬∑, s) is active, i.e. s ‚ààI(x),
then F(x, s) = f(x) and we conclude that F(x‚Ä≤, s) ‚â•F(x, s) for all x‚Ä≤ ‚ààB(x, r2) ‚à©C.
This shows that x locally minimizes all active functions F(¬∑, s) under the constraints ci(x) ‚â§0. Therefore, these functions
verify the following KKT conditions: for all s ‚ààI(x), there exists (Œªi(s))1‚â§i‚â§n such that:
‚àáxF(x, s) + Pn
i=1 Œªi(s)‚àáci(x) = 0
‚àÄi, Œªi(s) ‚â•0, Œªi(s)ci(x) = 0, ci(x) ‚â§0
As shown in [4], [25], the subgradient of an upper-C1 function f at x is the convex hull formed by the gradients of the
active functions F(¬∑, s):
‚àÇf(x) = co {‚àáxF(x, s) : s ‚ààI(x)}
Thus, gx ‚àà‚àÇf(x) can be written as:
gx =
p
X
j=1
asj‚àáxF(x, sj) , sj ‚ààI(x) ‚àÄj
where the asj ‚â•0 are such that Pp
j=1 asj = 1 (and p is at most the number of parameters plus one). Then, we have:
gx = ‚àí
p
X
j=1
asj
n
X
i=1
Œªi(sj)‚àáci(x) = ‚àí
n
X
i=1
Ô£´
Ô£≠
p
X
j=1
asjŒªi(sj)
Ô£∂
Ô£∏‚àáci(x) = ‚àí
n
X
i=1
¬µi‚àáci(x)
where ¬µi := Pp
j=1 asjŒªi(sj). For all i: ¬µi ‚â•0 (because all asj and Œªi(sj) are ‚â•0), and ¬µici(x) = 0 (because if ci(x) Ã∏= 0,
then all Œªi(sj) are 0). This proves Proposition 2.b).
Remark 1. Proposition 1.b) is similar to [25, Proposition 4], where it is shown that ‚Äùdirectional-stationarity‚Äù, i.e. the
assumption that f ‚Ä≤(x, d) ‚â•0 for any d ‚ààRk, implies that all subgradients are 0. Note that directional stationarity does not
imply that x minimizes f(x); for this, more assumptions would be required, e.g. convexity of the F(¬∑, s) [25, Theorem 10].
Proposition 2.a) is a generalization of [26, Theorem 3.1], originally for differentiable functions, to upper-C1 functions. To


the best of our knowledge, Proposition 2.b) is novel, and can also be seen as a speciÔ¨Åc case of the usual KKT conditions
for upper-C1 functions. It allows optimality to be checked with any subgradient, in contrast to the general nonsmooth case,
where only the existence of one subgradient satisfying KKT conditions is required.
B. Convergence of sequential quadratic programming (SQP) for upper-C1 functions
We now introduce the Sequential Quadratic Programming (SQP) algorithm to solve Problem (8). It is described in
Algorithm 1, as in [26] except that we replaced the gradient ‚àáf(x) by any subgradient gx ‚àà‚àÇf(x) in the quadratic problem
Q(x, H, gx) (equation (10)). See also [27] for a discussion when the penalty parameter r is variable. We do not detail how
the quadratic problem in Step 1 or the step size Œªk in Step 2 may be solved, or how Hk is updated in Step 3, as it does
not affect the convergence proof (as long as the conditions described in Algorithm 1 are satisÔ¨Åed)
Algorithm 1 Sequential Quadratic Programming (SQP) algorithm [26] for upper-C1 functions
Initialization: x0 ‚ààRk, H0 ‚ààRk√ók positive deÔ¨Ånite, r > 0, Œªmax > 0.
Step 1: Find a KKT point pk of the quadratic problem Q(xk, Hk, gxk) deÔ¨Åned in equation (10).
Step 2: Set xk+1 = xk + Œªkpk for any Œªk ‚àà[0, Œªmax] satisfying:
Œ∏r(xk+1) ‚â§
min
0‚â§Œª‚â§Œªmax Œ∏r(xk + Œªpk) + «´k
where Œ∏r is deÔ¨Åned in equation (11), and («´k) is a sequence of nonnegative numbers satisfying:
‚àû
X
i=0
«´i < ‚àû
Step 3: Update Hk+1 by some scheme that keeps it deÔ¨Ånite positive.
Proposition 3 extends the convergence result of SQP established in [26, Theorem 3.2] for differentiable objective functions
to the case of upper-C1 objective functions. Besides the upper-C1 condition of f, the same assumptions as in [26, Theorem
3.2] are considered.
Proposition 3 (Convergence of SQP for upper-C1 functions)
Let f be upper-C1 and the ci be continuously differentiable. Assume that the following conditions are satisÔ¨Åed:
(i) there exists Œ±, Œ≤ > 0 such that, for each k and for any x ‚ààRk:
Œ±xT x ‚â§xT Hkx ‚â§Œ≤xT x
(ii) For each k, there exists a KKT point of Q(xk, Hk, gxk) (equation (10)) with a Lagrange multiplier vector uk such
that ||uk||‚àû‚â§r (vector ‚àû-norm).
Then, any sequence (xk) generated by Algorithm 1 either terminates at a KKT point of the constrained optimization
problem (8), or any accumulation point ¬Øx with
S0(¬Øx) = {p : c(¬Øx) + ‚àác(¬Øx)T p < 0} Ã∏= ‚àÖ
is a KKT point of Problem (8).
Proof. Cf. Appendix. The proof follows that of [26, Theorem 3.2] and adapts it to the case where f is not differentiable but
only upper-C1. In particular, the upper semi-continuity of the Clarke subdifferential allows to maintain the argument linked
to the continuity of the gradient in the original proof. The existence of an accumulation point of the solutions pk of the
quadratic problems Q(xk, Hk, gxk) also follows from the submonotonicity of the subgradient of upper-C1 functions [11]
(cf. Lemma 1 in Appendix).
Proposition 2.b) establishes that local minima are necessarily KKT points for any subgradient, and Proposition 3 proves
the convergence to KKT points when using any subgradient. Consequently, the standard SQP algorithm can be applied to
upper-C1 functions, by providing any subgradient where the gradient is expected.
Remark 2. The purpose of our arguments for using smooth optimization is not to claim superiority over specialized nonsmooth
optimization methods. Instead, we emphasize that readily available algorithms (e.g., in MATLAB or Python toolboxes) can
be applied successfully and produce satisfactory results.


III. WORST CASE SEARCH IN CONSTRAINED PARAMETRIC SPACE
A. Problem formulation
In this section, the controller K is Ô¨Åxed and, thus, voluntarily omitted in the notations.
As in [2], worst-case stability is studied by maximizing the spectral abscissa of the closed-loop matrix A(Œ¥). The problem
(4) can also be written as the following constrained optimization problem:
minimize
Œ¥‚ààRk
a(Œ¥) := ‚àíŒ±(A(Œ¥))
subject to
‚àí1 ‚â§Œ¥i ‚â§1
ci(Œ¥) ‚â§0
(12)
Similarly for the performance problem (3), we deÔ¨Åne for the H‚àûnorm of a generic transfer function Tzw(s, Œ¥):
minimize
Œ¥‚ààRk
h‚àû(Œ¥) := ‚àí||Tzw(s, Œ¥)||‚àû
subject to
‚àí1 ‚â§Œ¥i ‚â§1
ci(Œ¥) ‚â§0
(13)
and for the (squared) H2 norm:
minimize
Œ¥‚ààRk
h2(Œ¥) := ‚àí||Tzw(s, Œ¥)||2
2
subject to
‚àí1 ‚â§Œ¥i ‚â§1
ci(Œ¥) ‚â§0
(14)
B. Properties of the objective functions
In this section, we consider a generic transfer function written as the Linear Fractional Transformation (LFT) [28, Chapter
10] Tzw(s, Œ¥) = Fu(M(s), ‚àÜ), as depicted in Figure 1, where ‚àÜ= diag(Œ¥iIni) (ni is the number of repetitions of Œ¥i). This
representation will be used to characterize either the internal stability, or the H‚àûor H2 norm of the transfer from w to z;
practical problems e.g. (2) can also be addressed after an appropriate partitioning.
M(s)
‚àÜ
w
p
q
z
Fig. 1: LFT representation of Tzw
The state-space representation of M(s) is written as:
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Ô£Æ
Ô£∞
Àôx
q
z
Ô£π
Ô£ª=
Ô£Æ
Ô£∞
A1
B1
B2
C1
D11
D12
C2
D21
D22
Ô£π
Ô£ª
Ô£Æ
Ô£∞
x
p
w
Ô£π
Ô£ª
p = ‚àÜq
‚áê‚áí
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
Ô£Æ
Ô£∞
Àôx
Àúq
z
Ô£π
Ô£ª=
Ô£Æ
Ô£∞
A1
B1
B2
C1
0
D12
C2
D21
D22
Ô£π
Ô£ª
Ô£Æ
Ô£∞
x
Àúp
w
Ô£π
Ô£ª
Àúp = e‚àÜÀúq
where, in the right equation, the system was rewritten with the change of variable:
e‚àÜ= (I ‚àí‚àÜD11)‚àí1‚àÜ= ‚àÜ(I ‚àíD11‚àÜ)‚àí1
(15)
to have no direct transfer from Àúp to Àúq. This change of variable is the same as in [28, Section 12.3.4], with the uncertainty
block instead of a feedback controller, and will be useful to study the H2 norm.
1) H2 norm (function h2):
Proposition 4 (Differentiability of h2)
Let us assume D22 = 0, and either D12 = 0 or D21 = 0. Then, h2 is deÔ¨Åned and differentiable in
Ds = {Œ¥ ‚ààD, Tzw(s, Œ¥) is internallystable}
and its gradient is given in equation (18).
Proof. The assumption D22 = 0 is necessary to ensure Ô¨Åniteness of the H2 norm in the nominal case ‚àÜ= 0. The assumption
D12 = 0 or D21 = 0 is done for the same reason for ‚àÜÃ∏= 0. The differentiability of h2 in Ds = {Œ¥ ‚ààD, Tzw(s, Œ¥) is stable}
was shown in [29, Section 3]; it was originally derived for a controller rather than an uncertainty block, but the validity


of the result extends straightforwardly to the latter. Let us write the state-space matrices of the transfer from w to z after
closing the loop between p and q:
A(Œ¥) = A1 + B1 e‚àÜC1 , B(Œ¥) = B2 + B1 e‚àÜD12 , C(Œ¥) = C2 + D21 e‚àÜC1 , D(Œ¥) = D21 e‚àÜD12 = 0
(16)
Then, the squared H2 norm is:
||Tzw(s, Œ¥)||2
2 = Tr
 B(Œ¥)T X(Œ¥)B(Œ¥)

= Tr
 C(Œ¥)Y (Œ¥)C(Œ¥)T 
where X(Œ¥) and Y (Œ¥) are solutions of the Lyapunov equations:
A(Œ¥)T X(Œ¥) + X(Œ¥)A(Œ¥) + C(Œ¥)T C(Œ¥) = 0
A(Œ¥)Y (Œ¥) + Y (Œ¥)A(Œ¥)T + B(Œ¥)B(Œ¥)T = 0 .
The derivative of h2 at point Œ¥ for the variable e‚àÜ, noted h‚Ä≤
2(e‚àÜ)de‚àÜ, is obtained from [30, Lemma 3.1] or equivalently [31,
Section 2.1], also originally derived for a controller and adapted here for the uncertain block e‚àÜ:
h‚Ä≤
2(e‚àÜ)de‚àÜ= Tr

‚àáe‚àÜh2(Œ¥)T de‚àÜ

where the gradient ‚àáe‚àÜh2(Œ¥) is given in the same references:
‚àáe‚àÜh2(Œ¥) = ‚àí2
 BT
1 X(Œ¥) + DT
21C(Œ¥)

Y (Œ¥)CT
1 ‚àí2BT
1 X(Œ¥)B(Œ¥)DT
12 .
Finally, differentiating equation (15):
de‚àÜ= (I ‚àí‚àÜD11)‚àí1d‚àÜ
 I + D11(I ‚àí‚àÜD11)‚àí1‚àÜ

and using the same notation as in [2]:
‚àÜi := ‚àÇ‚àÜ
‚àÇŒ¥i
,
(17)
the derivatives of h2 read:
‚àÇh2
‚àÇŒ¥i
= ‚àí2Tr
 ‚àáe‚àÜh2(Œ¥)T (I ‚àí‚àÜD11)‚àí1‚àÜi
 I + D11(I ‚àí‚àÜD11)‚àí1‚àÜ

.
(18)
2) H‚àûnorm (function h‚àû):
Proposition 5 (Regularity of h‚àû[5], [3], [2])
a) h‚àûis locally Lipschitz and thus Clarke subdifferentiable (in the sense of [4]) everywhere in
Ds = {Œ¥ ‚ààD, Tzw(s, Œ¥) is internally stable} .
b) h‚àûis upper-C1 everywhere in Ds.
c) h‚àûis differentiable in Ds when only one frequency is active and of multiplicity one; in this case, its gradient is given
in equation (19).
Proposition 5.a) is proved in [2, Proposition 1] and follows the work of [5] and [3]. The general subgradient expression is
provided in these references, but we will not use it in this paper. b) is proved in [2, Proposition 2]. c) immediately follows
from a), and the expression is also provided in [2, Remark 5]: using the same notations, let us deÔ¨Åne Tqw and Tzp as:

‚àó
Tqw(s, Œ¥)
Tzp(s, Œ¥)
Tzw(s, Œ¥)

=
 0
I
I
‚àÜ

‚ãÜM(s)
with ‚ãÜdenoting the redheffer star product. The transfer functions Tzw, Tqw and Tzp correspond to the transfer between
the inputs p, w and outputs q, z of the matrix M(s) as in Figure 1, but after closing the loop with the block ‚àÜ. If œâ0 is
the single active frequency, such that the multiplicity of ¬ØœÉ(Tzw(jœâ0, Œ¥)) is 1, h‚àûis differentiable and, as shown in [2], its
derivatives read:
‚àÇh‚àû
‚àÇŒ¥i
= ‚àíTr
 Re(Tqw(jœâ0, Œ¥)pœâ0qH
œâ0Tzp(jœâ0, Œ¥))T ‚àÜi

(19)
Where pœâ0 and qœâ0 are the normalized right and left singular vectors of Tzw(jœâ0, Œ¥) associated with ¬ØœÉ(Tzw(jœâ0, Œ¥)) (which
is equal to ‚àíh‚àû(Œ¥)).


From the results of Section II and Proposition 5.b), we deduce that we can use smooth optimization, and in particular
SQP (Algorithm 1), to solve Problem (13). In particular, let us deÔ¨Åne the direction dŒ¥ such that its components are deÔ¨Åned
as in equation (19) (even when h‚àûis not differentiable), i.e. the i-th component of dŒ¥ reads:
dŒ¥,i = ‚àíTr
 Re(Tqw(jœâ0, Œ¥)pœâ0qH
œâ0Tzp(jœâ0, Œ¥))T ‚àÜi

where œâ0 is an active frequency ‚Äì but not necessarily the only one, and the multiplicity of ¬ØœÉ(Tzw(jœâ0, Œ¥)) is not necessarily 1 ‚Äì
and pœâ0 and qœâ0 are the corresponding normalized right and left singular vectors of Tzw(jœâ0, Œ¥). Then, dŒ¥ is a subgradient
of h‚àû(this is straightforward from the expression of the subgradient given in [2, Section IV-1]); by Proposition 2 and
Theorem 3, it can legitimately be used in SQP as if it were the gradient of a differentiable function.
Remark 3. Proposition 2.b) is not anecdotal in this application. Indeed, after optimization of the controller, it is frequent
to have multiple active frequencies. Therefore, it is important for the optimality criterion to be valid at a nonsmooth point,
even if the function will most often be differentiable during the optimization.
Remark 4. In contrast, minimizing the lower-C1 function ‚àíh‚àû(Œ¥), i.e. minimizing the H‚àûnorm, would be a more complex,
genuinely nonsmooth problem. In particular, an unconstrained minimum may occur at a point where many subgradients are
not zero (as a more simple example, consider f : x ‚Üí|x|, which is lower-C1). For this problem, nonsmooth techniques in
the literature include multidirectionnal search [32], gradient sampling [33], or Clarke subdifferential-based [3], [34]. This
is also pointed out in [2] as a fundamental difference between min-max and min-min (or max-max) programs, the former
(e.g. minimizing the H‚àûnorm) being genuinely non-smooth while the latter (e.g. maximizing the H‚àûnorm or equivalently
minimizing h‚àû) having the favorable properties demonstrated above.
3) Spectral abscissa (function a):
The case of the spectral abscissa is slightly less favorable than the H‚àûnorm. We recall that simple eigenvalues (i.e. those
of multiplicity one) are differentiable [35]. As in [2], we call ‚Äùactive eigenvalues‚Äù all eigenvalues whose real part is equal
to the spectral abscissa.
Proposition 6 (Regularity of a [2], [36])
a) If all active eigenvalues of A(Œ¥) are semi-simple (i.e. their algebraic and geometric multiplicity are equal), then a is
locally Lipschitz and thus Clarke subdifferentiable at Œ¥.
b) If all active eigenvalues of A(Œ¥) are simple at Œ¥, then a is upper-C1 at Œ¥.
c) If A(Œ¥) has only one active eigenvalue and it is simple, then a is differentiable at Œ¥. With the notation of equations (16)
and (17), the derivative of a with regard to Œ¥i reads:
‚àÇa
‚àÇŒ¥i
= ‚àíTr
 ‚àÜT
i Re((I ‚àíD11‚àÜ)‚àí1C1viuH
i B1(I ‚àí‚àÜD11)‚àí1)T 
(20)
where vi and ui are right and left eigenvectors associated with the active eigenvalue, normalized such that uH
i vi = 1.
Proposition 6.a) was established in [2] following the earlier work of [36]. These references build on the study of [37]
concerning the directional derivatives of the spectral abscissa. b) is also shown in [2], it simply follows from the fact that
the spectral abscissa is the maximum of the real parts of the eigenvalues, which are differentiable when the eigenvalues are
simple [35]. For c), the expression (20) is straightforward from the expression of the Clarke subdifferential given in [2].
Remark 5. Additionally, if there are two active eigenvalues and they are complex conjugate eigenvalues, a is also differentiable
and the gradient given above remains valid for either of the two eigenvalues [36].
Remark 6. Although the assumption of semi-simplicity is required for the deÔ¨Ånition of the Clarke subdifferential, the
numerical experiments reported in [2] show that their bundle approach, based on Clarke subdifferentials, performs well
in practice even without explicitly verifying this assumption.
Remark 7. As for the H‚àûnorm, minimizing the spectral abscissa is a more complex problem; in the literature, this is
addressed with bundle methods [38], [39], gradient bundle [40], gradient sampling [33], Clarke subdifferential-based [36].
In this paper, as for h‚àû, we rely on the upper-C1 property of a of Proposition 6.b) and on the results of Section II,
when active eigenvalues are simple. Our numerical experiments are satisfactory; however, the case of non-simple active
eigenvalues is admittedly a limitation of using smooth optimization algorithms for the worst-case search in stability.
C. Choice of optimization algorithms
Problems (12), (13) and (14) are constrained optimization problems involving the nonsmooth functions a, h‚àû, and the
differentiable function h2. We propose to use either Particle Swarm Optimization or Monte-Carlo sampling for global


exploration of the parametric space, and then Sequential Quadratic Programming for local exploitation. As demonstrated in
Section II, this procedure will converge to KKT points of the optimization problems.
1) Sequential Quadratic Programming (SQP):
SPQ is described in Algorithm 1 and, as discussed in Section II, may be used to minimize upper-C1 functions. In our
numerical application, we used MATLAB routine FMINCON [41]. In FMINCON, the matrix H serves as an approximation
of the Hessian matrix of the Lagrangian, iteratively updated with the Broyden-Fletcher-Goldfarb-Shanno (BFGS) method.
It is worth noting that BFGS was observed to perform well in [36] even for a non-smooth objective function (the spectral
abscissa).
2) Particle swarm optimization (PSO):
PSO is a global optimization method that handles nonsmooth functions. It only relies on the evaluation of the function
and does not depend on (sub)gradient information or on the regularity properties discussed in Section III-B; thus, it may
help circumvent limitations encountered when the spectral abscissa fails to be upper-C1, or even Clarke subdifferentiable.
The nonlinear constraint is treated with a barrier method to penalize non admissible solutions: we reformulate problem (13)
as:
minimize
Œ¥‚ààRk
h‚àû(Œ¥) + œÑ max(0, c(Œ¥))
subject to
‚àí1 ‚â§Œ¥i ‚â§1
and problems (12) and (14) can be treated similarly. The parameter œÑ can be set to a high value, and iteratively increased
if necessary until a solution Œ¥‚àóverifying c(Œ¥‚àó) ‚â§0 is found. The bounds on the Œ¥i are enforced by projecting the particles
positions into the admissible space at each iteration. In our numerical testings, we used MATLAB routine PSO described
in [42]; PSO was used as a method to explore the parametric space (and the choice of parameters was done accordingly, as
discussed in Section V-C), with local exploitation being performed by a subsequent SQP.
3) Monte-Carlo (MC) sampling:
Monte Carlo sampling is applied as follows: randomly pick a sample Œ¥ in the unit hypercube (considering for example
uniform distributions for all parameters); evaluate c(Œ¥): if positive, discard Œ¥, otherwise, evaluate the function a(Œ¥) (respec-
tively h‚àû(Œ¥) or h2(Œ¥)); repeat until having N function evaluations. The worst-case Œ¥‚àócorresponds to the lowest value of a
(respectively h‚àûor h2(Œ¥)). In our testings, Monte Carlo will also be followed by SQP for local exploitation.
In such a worst-case search problem, the number N of function evaluations can be chosen to verify:
N ‚â•
ln(Œ≥)
ln(1 ‚àí«´)
where Œ≥ and «´ serve as conÔ¨Ådence and accuracy levels to guarantee the probability [10]:
P(P(f(Œ¥) > f(Œ¥‚àó) ‚â§«´) ‚â•1 ‚àíŒ≥
(21)
for an objective function f (in our case: a(Œ¥), h‚àû(Œ¥) or h2(Œ¥)). Note that this bound is independent from the number of
uncertain parameters, from their variation ranges or distributions.
IV. ROBUST CONTROL IN CONSTRAINED PARAMETRIC SPACE
This Section addresses robust controller optimization i.e. problems (1) and (2) in parametric space D given in (5).
A. Robust controller optimization algorithm
The Algorithm 2, described in a form that solves the standard H‚àûcontrol problem (1) ‚Äì the multi-objectives formulation
is tackled in Section IV-B ‚Äì follows the approach proposed in [2] that relies on iteratively constructing a subset Da ‚äÇD
of so-called active conÔ¨Ågurations as follows. Step 1 optimizes the controller for all current active conÔ¨Ågurations. It uses the
nonsmooth optimization algorithm of [3] implemented in the routine SYSTUNE. Step 2 addresses the worst-case search in
stability as described in Section III; if a worst-case conÔ¨Åguration, i.e. a Karush-Kuhn-Tucker (KKT) point of the optimization
problem, is found that leads to a spectral abscissa greater than a tolerance Œ±max, it is added to Da. It is also possible to
identify multiple KKT points during Step 2. Similarly, Step 3 tackles the worst-case search in performance and adds to Da
the worst-case conÔ¨Åguration(s) that degrade the performance by more than a tolerance «´. Finally, Step 4 performs a more
exhaustive worst-case search, meaning that the optimization parameters are tuned to increase coverage of the parameter space
and ensure a more thorough exploration of potential worst-case conÔ¨Ågurations, while in Steps 2 and 3 they are chosen to
prioritize fast convergence to KKT points; additional quantitative details are provided in the application of Section V-D. For


Steps 2, 3 and 4, the global exploration may be performed either with Particle Swarm Optimization (PSO), or Monte-Carlo
(MC) if stochastic guarantees are sought; in both cases, a subsequent Sequential Quadratic Programming (SQP) reÔ¨Ånes the
search until Ô¨Ånding a KKT point.
Algorithm 2 Robust control optimization with constrained uncertainties
Initialization: Initialize the set of active conÔ¨Ågurations as Da = {0}.
Step 1: Multi-model synthesis.
Compute optimal controller K‚àó= arg minK‚ààK maxŒ¥‚ààDa ||Tzw(s, K, Œ¥)||‚àûusing nonsmooth optimization (SYSTUNE).
Step 2: Destabilization.
Identify one or multiple KKT point(s) for the problem: Œ¥‚àó= arg maxŒ¥‚ààD Œ±(A(K‚àó, Œ¥)) using PSO/MC+SQP.
If Œ±(A(K‚àó, Œ¥)) > Œ±max, add Œ¥‚àóto Da and go back to step 1.
Otherwise continue to step 3.
Step 3: Degrade performance.
Identify one or multiple KKT point(s) for the problem: Œ¥‚àó= arg maxŒ¥‚ààD ||Tzw(s, K‚àó, Œ¥)||‚àûusing PSO/MC+SQP.
If a destabilizing Œ¥ is found during this optimization, go back to step 2 and start SQP directly from Œ¥.
Else, if ||Tzw(s, K‚àó, Œ¥‚àó)||‚àû> (1 + «´) maxŒ¥‚ààDa ||Tzw(s, K‚àó, Œ¥)||‚àû, add Œ¥‚àóto Da and go back to step 1.
Otherwise, go to step 4.
Step 4: Validation
Perform exhaustive worst-case search in stability and performance.
If a conÔ¨Åguration Œ¥‚àónot respecting criteria of step 2 or 3 is found, add Œ¥‚àóto Da and go back to step 1.
Otherwise, terminate.
B. Multi-objective formulation
Algorithm 2 is presented to address the standard problem formulation (1) involving a single H‚àûcriterion. We note that
this formulation also directly addresses the multi-objective problem:
minimize
K‚ààK
max
1‚â§i‚â§nmax
Œ¥‚ààD Œ±i||Tziwi(s, K, Œ¥)||‚àû
since it is equivalent to a single objective problem (e.g. as in [43], [1]):
max
1‚â§i‚â§nmax
Œ¥‚ààD Œ±i||Tziwi(s, K, Œ¥)||‚àû= max
Œ¥‚ààD ||diag(Œ±iTziwi(s, K, Œ¥))||‚àû.
(22)
In our numerical implementation, we used the expression on the left side of equation (22); indeed, it was faster to compute
the norm of each requirement, than the norm of the block diagonal system.
More generally, we consider the multi-objectives problem (2). As explained in [44], the controller optimization of Step 1
treats it as :
minimize
K‚ààK
max

max
Œ¥‚ààD ||Tz1w1(s, K, Œ¥)|| , Œ∑ max
2‚â§i‚â§nmax
Œ¥‚ààD ||Tziwi(s, K, Œ¥)||

where ||¬∑|| may refer to the H2 or H‚àûsystem norm, and where Œ∑ is adjusted during the optimization with a penalty approach.
In our worst-case performance searches (in Steps 3 and 4), we use the following normalization, such that the performance
degradation test of Step 3 (i.e. ||Tzw(s, K‚àó, Œ¥‚àó)||‚àû> (1 + «´) maxŒ¥‚ààDa ||Tzw(s, K‚àó, Œ¥)||‚àû, in the single objective case)
becomes, in the multi-objectives case:
max

1
(1 + «´1)Œ≤ max
Œ¥‚ààD ||Tz1w1(s, K, Œ¥)|| ,
1
(1 + «´2) max
2‚â§i‚â§nmax
Œ¥‚ààD ||Tziwi(s, K, Œ¥)||

> 1
(23)
where Œ≤ is the soft performance obtained in Step 1:
Œ≤ = max
Œ¥‚ààDa ||Tz1w1(s, K‚àó, Œ¥)||
i.e. the algorithm has converged when the worst-case search degrades the soft requirement by less than 1 + «´1, and the hard
requirements are less than 1+«´2. Finally, we point out that, in our implementation, the PSO computes all norms involved in
equation (23) and determines their maximum; whereas the subsequent SQP only evaluates the transfer function that achieved
this maximum.


V. APPLICATION: A LARGE FLEXIBLE SPACECRAFT
A. Plant model and uncertain parameters
The benchmark used in this study is designed to be challenging regarding robustness. We consider a spacecraft composed
of one rigid body connected to two large Ô¨Çexible solar panels. The clamped-free natural frequencies are 0.20, 0.50, 0.75
and 0.85 rad/s for each panel. The resulting 8 nominal free-free frequencies are between 0.20 and 4.2 rad/s for the whole
spacecraft. Uncertainties are considered on various mechanical properties:
‚Ä¢ Each clamped-free frequency exhibits a common 10% across both panels, along with an additional 5% asymmetric
uncertainty. Modal damping is 0.001 for each clamped-free mode.
‚Ä¢ The mass, center of mass, inertia (MCI) properties of the solar panel are uncertain, as well as the modal participation
factors of the Ô¨Çexible modes.
‚Ä¢ The angle between the central body and the solar arrays may have any value between ‚àíœÄ and +œÄ.
‚Ä¢ The central body also has uncertain MCI properties.
‚Ä¢ We also consider an uncertain stiffness and damping in the rotation of the solar array, as a simple solar array driving
mechanism (SADM) model.
In total, there are 43 uncertain parameters Œ¥i (normalized such that ‚àí1 ‚â§Œ¥i ‚â§1, without loss of generality) regrouped in a
vector Œ¥. Noting MP (Œ¥) the mass matrix at attachment point P of a solar panel, and LP (Œ¥) the matrix of modal participation
factors, the robustness analysis should exclude any conÔ¨Åguration Œ¥ such that the residual mass matrix deÔ¨Åned in equation
(24) is not positive deÔ¨Ånite (indeed, such conÔ¨Ågurations do not represent a physical system). Hence the nonlinear constraint:
Mr(Œ¥) := MP (Œ¥) ‚àíLT
p (Œ¥)Lp(Œ¥) ‚™∞0
(24)
which can also be written under a scalar form:
c(Œ¥) := Œ±(‚àíMr(Œ¥)) ‚â§0 .
(25)
The spacecraft model G(s, Œ¥) is built with the multibody approach detailed in [45] and implemented in the Satellite
Dynamics Toolbox Library (SDTlib) [46], [47]. The block ‚àÜG of the Linear Fractional Representation (LFR) model, such that
G(s, Œ¥) = Fu(MG(s), ‚àÜG) (upper LFT), has size 204. We emphasize that this model contains all parametric conÔ¨Ågurations
in a continuous manner, deÔ¨Åned at each subsystem level based on the physics equations without any interpolation or
other approximation (besides the linearity assumption). The LFR model of the spacecraft includes all conÔ¨Ågurations for
‚àí1 ‚â§Œ¥i ‚â§1 even though only ‚àº22% of them respect the nonlinear constraint (25).
Remark 8. In addition to providing the analytical expressions of the gradients given in Section III, the LFR representation
also enables fast model evaluation at given parametric conÔ¨Åguration by simply substituting the ‚àÜG block.
B. Closed loop and control problem
The benchmark focuses on the attitude control of the satellite described above to follow a reference r. The control input u
of the plant G(s, Œ¥) is the torque applied to the satellite (e.g. by reaction wheels, thrusters...) and the output vector contains
the 3 angle measurements polluted by some noise n. The closed loop is represented in Figure 2, where d(s) represents
avionics: a 2-nd order Pade approximation of a 0.125s delay, and a 2-nd order low-pass Ô¨Ålter with a cut-off frequency of
10 rad/s representing reaction wheel dynamics. We note K(s) the set of controllers K(s) of the desired structure: one 4-th
order controller per spacecraft axis, each one taking the measured angle and rate as inputs and generating a control torque,
resulting in 24 decision parameters per controller (72 in total). The closed-loop plant has 50 states.
G(s, Œ¥)
K(s)
e
r
s
n
u
d(s)
Fig. 2: Benchmark: closed-loop system
The control problem consists in placing a control bandwidth of 0.1 rad/s (hence interacting with the uncertain Ô¨Çexible
modes) while ensuring a modulus margin of 0.5 and minimizing the variance of the actuator command in response to
measurement noise. It reads:
minimize
K‚ààK
max
Œ¥‚ààD ||Tn‚Üíu(s, K, Œ¥)||2
2
subject to
max
Œ¥‚ààD || 1
2Ts‚Üíu(s, K, Œ¥)||‚àû< 1
max
Œ¥‚ààD ||WTr‚Üíe(s, K, Œ¥)||‚àû< 1
max
Œ¥‚ààD Œ±(A(K, Œ¥)) < ‚àí10‚àí7
(26)


where D is deÔ¨Åned in (5) with the nonlinear constraint (25), the factor
1
2 in the 2nd requirement ensures the desired
modulus margin, and W =
10s+1
2(10s+0.01)I3 is a weighting Ô¨Ålter to impose the desired bandwidth of 0.1 rad/s. The last
requirement of problem (26) ensures closed-loop stability with some tolerance, where A(K, Œ¥) is the matrix A of the
state-space representation of the closed-loop system.
C. Worst-case search
In this section, we present the worst-case search for the spectral abscissa and the H‚àûnorm, as presented in Section III.
We selected three controllers K1, K2, K3 obtained at early iterations of the robust controller tuning presented in Section V-
D and analyze the robustness of the closed-loop system with three Test cases. The tests are ran on a 12th Gen Intel(R)
Core(TM) i7-12700H 2.30 GHz, with 14 cores and 16GB of RAM. Computation times are provided for reference, but they
may vary depending on hardware, software conÔ¨Åguration, implementation details, optimization parameters, etc.
1) Test case 1: spectral abscissa (multiple local optima):
Test case 1 illustrates how the proposed approaches perform in presence of several local optima, in different regions of
the parametric space, that are not particularly rare. We search for maxŒ¥‚ààD Œ±(A(K1, Œ¥)).
a) SQP
We ran the Sequential Quadratic Programming (SQP) algorithm from 100 random initial points. As termination criteria, we
set 10‚àí6 as optimality tolerance (KKT stationarity condition), and 10‚àí8 as step tolerance (step size between two iterations).
The resulting worst-case spectral abscissas Œ±(A(Œ¥‚àó
SQP)) = ‚àía(Œ¥‚àó
SQP) of each run are in Figure 3a, and suggest the presence
of several local optima, which highlights the limitation of such a local method. These various local optima may correspond
to signiÔ¨Åcantly different parametric conÔ¨Ågurations. For example, the worst case 0.135 has the value -1.0 for the (normalized)
value of one of the moments of inertia of the solar panel, -0.09 and 1.0 for the modal participation factors of the clamped-free
modes 1 and 3 in rotation around the same axis; in contrast, the local optimum 0.007 has -0.30, -1.0 and -0.87 respectively for
these three parameters. Figure 3b presents the poles map for the initial poles (for the random initialization of the parameters)
and Ô¨Ånal poles (corresponding to the worst case) for one of the runs that converged to the suggested global optimum.
Excluding the runs that did not detect instability (each of which took less than 0.1s), the remaining runs took between
2.5 and 78s (average: 21s ‚Äì regarding total computation time, we recall that each SQP run is inherently sequential, but that
the 100 runs are executed in parallel).
b) PSO, PSO + SQP
The parameters of the Particle Swarm Optimization (PSO) were chosen as follows to favor global exploration over local
exploitation. We set a range of 0.6 to 1.1 for the adaptive inertias (‚ÄôInertiaRange‚Äô option in MATLAB). Iterations terminate
when performance is increased by less than 10% (‚ÄùFunctionTolerance‚Äô) across 20 last iterations (‚ÄôMaxStallIterations‚Äô). For
a given computational budget, because PSO is sensitive to initialization [48], running several independent instances with
different initializations can yield better results than increasing the number of particles or tightening the termination tolerance.
Therefore, we performed 100 independent runs with the parameters given above, each with 500 particles (‚ÄôSwarmSize‚Äô) ‚Äì cf.
also [49] for a discussion on population size in PSO. All other parameters were set to MATLAB‚Äôs default settings. Bearing
in mind that our parameter choices were speciÔ¨Åcally tuned for multiple fast independent runs rather than to maximize the
reliability of a single run, the results should be interpreted to determine how many such runs are required to reliably identify
a worst case. We see that, with a few runs, we are able to consistently identify the worst-case conÔ¨Åguration that was most
often missed by the local SQP alone.
For each run, the computations of the 500 particles were parallelized over 14 cores. Each run took between 6s and 8s
(average: 7s) with 11000 model evaluations. Each run was followed by SQP (starting from the identiÔ¨Åed worst case), each
between 37 and 97s (average: 77s) ; these SQPs were parallelized. The results in Figure 3c show that the (suggested) global
optimum can be consistently found using a few random initializations of PSO+SQP.
c) MC, MC + SQP
To enable a fair comparison with PSO, (i) we performed a total of NMC =1.1e6 evaluations of the objective function a,
matching the total number of objective function evaluations of the PSO across all 100 runs, and (ii) we divided the NMC
random samples into 100 groups, that we call Monte-Carlo (MC) experiments. MC performed almost as well as PSO, cf.
Figure 3d. In all runs, the subsequent SQP signiÔ¨Åcantly improves the result. Each MC run took about 6.2s, and the SQP
runtimes were similar to the PSO case.
We mention that 78% of the drawn samples were not admissible (g(Œ¥) > 0) and were therefore discarded before evaluation
of a(Œ¥). About 92% of the admissible conÔ¨Ågurations were destabilizing (a(Œ¥) < 0). We also mention that the total number


0
20
40
60
80
100
Random initializations
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Worst-case spectral abscissa
SQP
(a) SQP, with 100 random initializations
-0.8
-0.6
-0.4
-0.2
0
0.2
0
1
2
3
4
5
5
4
3
2
1
0.75
0.48
0.32
0.23
0.16
0.11
0.07
0.035
Initial poles
Final poles
(b) Poles map (zoomed) for a SQP run
0
20
40
60
80
100
Random initializations
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Worst-case spectral abscissa
PSO
PSO+SQP
(c) PSO and PSO+SQP, with random 100 initializations
0
20
40
60
80
100
Independent runs
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Worst-case spectral abscissa
MC
MC+SQP
(d) MC and MC+SQP, repeated 100 times
Fig. 3: Worst-case spectral abscissa for Test case 1
of runs NMC veriÔ¨Åes NMC ‚âàln(Œ≥)/ln(1 ‚àí«´) with the values Œ≥ = «´ =1e-5, which guarantees as in equation (21) that the
worst-case a(Œ¥‚àó
MC) found through all samples of Figure 3d (without considering the subsequent SQP) covers 99.999% of the
probability distribution of a(Œ¥) with a conÔ¨Ådence level of 99.999%. These observations suggest that the worst case around
0.136 is rare, even though unstable conÔ¨Ågurations are frequent in Test case 1.
2) Test case 2: spectral abscissa (rare worst case):
Test case 2 illustrates how the proposed approaches perform when the destabilization is rare. Indeed, only ‚àº0.018% of
the admissible parametric space (as approximated by the MC experiments) yields unstability of A(K2, Œ¥). We search for
maxŒ¥‚ààD Œ±(A(K2, Œ¥)).
Most SQP runs remained stuck on the local optimum Œ±(A(Œ¥‚àó
SQP)) = ‚àía(Œ¥‚àó
SQP) = ‚àí2e‚àí7 that occupies most of the para-
metric space (Figure 4a). On the other hand, PSO+SQP (Figure 4c) more consistently Ô¨Ånds the destabilizing conÔ¨Ågurations.
PSO runs required more function evaluations than Test case 1: 1525500 across the 100 runs, for a runtime ranging from 6s
to 57s with an average of 11s. MC (again executed with the same total number of objective function evaluations as PSO
for fair comparison) is also able to detect unstability (Figure 4d), but it is signiÔ¨Åcantly outperformed by PSO (compare the
blue crosses of Figures 4c and 4d). MC+SQP performs decently but is slightly less reliable than PSO+SQP.
3) Test case 3: H‚àûnorm:
For controller K3, we applied the methods of Test cases 1 and 2 and did not Ô¨Ånd any destabilizing conÔ¨Åguration
for A(K3, Œ¥). Thus, we search for the worst-case H‚àûnorm: maxŒ¥‚ààD || 1
2Ts‚Üíu(s, K3, Œ¥)||‚àû(2nd control requirement of
Problem (26)). We note that the objective function is longer to evaluate than in previous Test cases 1 and 2.


0
20
40
60
80
100
Random initializations
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Worst-case spectral abscissa
SQP
(a) SQP, with 100 random initializations
-1
-0.5
0
0.5
1
0
2
4
6
8
10
12
14
14
12
10
8
6
4
2
0.65
0.4
0.28
0.19
0.135
0.095
0.06
0.03
Initial poles
Final poles
(b) Poles map (zoomed) for a SQP run
0
20
40
60
80
100
Random initializations
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Worst-case spectral abscissa
PSO
PSO+SQP
(c) PSO and PSO+SQP, with random 100 initializations
0
20
40
60
80
100
Independent runs
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Worst-case spectral abscissa
MC
MC+SQP
(d) MC and MC+SQP, repeated 100 times
Fig. 4: Worst-case spectral abscissa for Test case 2
The results are shown in Figure 5. The SQP runs took between 38s and 1172s (average: 591s). The PSO individual
runtimes ranged from 72 to 126s (average: 85s), and MC around 95s on average. Here, PSO tends to get stuck in the local
optimum 1.15, whereas MC+SQP more frequently converges to the suggested global optimum. In both cases, the subsequent
SQP improves the result of PSO or MC alone.
D. Robust control
In this section, we solve Problem (26) using Algorithm 2.
1) Implementation details:
In the following, let us call problematic conÔ¨Åguration any conÔ¨Åguration that does not respect the criterion of either Step 2
(i.e. such that Œ±(A(K‚àó, Œ¥)) > Œ±min) or Step 3 (i.e. such that ||Tzw(s, K‚àó, Œ¥‚àó)||‚àû> (1 + «´) maxŒ¥‚ààDa ||Tzw(s, K‚àó, Œ¥)||‚àû
or its multi-objectives counterpart of equation (23)). Below we give implementation details regarding the various steps of
Algorithm 2.
Step 1: Multi-models controller synthesis
SYSTUNE is initialized with the controller obtained at previous iteration along with 13 random initializations. If no
satisfactory controller is found, the process is repeated with new random initializations until one is obtained. In principle, a
maximum number of attempts could be enforced to declare the problem infeasible, but this option was not activated, as a
feasible solution was always found in our experiments.


0
20
40
60
80
100
Random initializations
0.7
0.8
0.9
1
1.1
1.2
1.3
1.4
Worst-case H
 norm
SQP
(a) SQP, with 100 random initializations
Frequency (rad/s)
Singular Values (dB)
10-2
100
102
-50
-40
-30
-20
-10
0
10
Requirement
Random samples
Local optima found with SQP
(b) Sigma plot: 100 random samples and a few KKT points
0
20
40
60
80
100
Random initializations
0.7
0.8
0.9
1
1.1
1.2
1.3
1.4
Worst-case H
 norm
PSO
PSO+SQP
(c) PSO and PSO+SQP, with random 100 initializations
0
20
40
60
80
100
Independent runs
0.7
0.8
0.9
1
1.1
1.2
1.3
1.4
Worst-case H
 norm
MC
MC+SQP
(d) MC and MC+SQP, repeated 100 times
Fig. 5: Worst-case (normalized) H‚àûnorm for Test case 3
Steps 2 and 3: Worst-case searches
Compared to the choice of parameters of Section V-C, here we reduced the swarm size to 100 and we relaxed the PSO
convergence criterion: iterations terminate when performance is increased by less than 10% across 10 last iterations. For
SQP, we reduced the step tolerance from 1e-8 to 1e-6. The objective is to speed up the detection of active conÔ¨Ågurations in
most iterations, relying on Step 4 to perform a Ô¨Åner validation. Below, we present three different strategies for the worst-case
searches.
Strategy 1
We run a single instance of PSO, followed by SQP. Although, as seen in Section V-C, this does not always converge
to the global optimum, we prioritize computational speed by stopping at the Ô¨Årst KKT point for several reasons. First,
each KKT point may be valuable to add to the active conÔ¨Ågurations even if it is not the global worst-case for the current
controller. Second, because multiple iterations are performed, any missed problematic conÔ¨Åguration can be detected in
subsequent iterations. Third, if stability is validated in Step 2 but a destabilizing conÔ¨Åguration is discovered when degrading
performance in Step 3, the process returns to Step 2. Fourth, a more exhaustive search is carried out in Step 4, allowing a
return to previous iterations if a problematic conÔ¨Åguration is identiÔ¨Åed, while limiting the number of such more expensive
searches. The resulting (single) KKT point, if problematic, is added to the active conÔ¨Ågurations.
Strategy 2
Strategy 2 is the same as Strategy 1, except that the PSO is stopped as soon as a problematic conÔ¨Åguration is found (using
‚ÄôObjectiveLimit‚Äô option in MATLAB); the PSO is then followed by SQP.
Strategy 3
In Strategy 3, we perform 4 instances of PSO+SQP and obtain 4 KKT points Œ¥‚àó
i . For clarity, let us assume that they are


all problematic conÔ¨Ågurations. The worst case among those 4, noted Œ¥‚àó
1, is added to the active conÔ¨Ågurations. Then, we
compute the distance |Œ¥‚àó
2 ‚àíŒ¥‚àó
1|; if the distance exceeds a speciÔ¨Åed threshold, Œ¥‚àó
2 is also added to the active conÔ¨Ågurations.
The procedure is repeated for Œ¥‚àó
3 and Œ¥‚àó
4: each Œ¥‚àó
i is added to the active scenarios only if its distance from all previously
selected points exceeds the threshold. The threshold is chosen as half of the hypercube diagonal of the parameter space,
i.e.,
‚àö
k, where k is the number of uncertain parameters. This choice limits the number of active scenarios by enforcing a
minimum spatial separation, thereby ensuring that only signiÔ¨Åcantly distinct worst-case conÔ¨Ågurations are retained. Indeed,
the computation time of the multi-models controller synthesis (Step 1) increases with the number of active conÔ¨Ågurations.
Step 4: validation
In Step 4, we run up to N instances of PSO. If a problematic conÔ¨Åguration is found, we run SQP, and add the resulting
worst case to the active conÔ¨Ågurations. Otherwise, we run SQP on all N instances. In other words, Step 4 operates like
Section V-C when no problematic conÔ¨Åguration is found, but terminates earlier when one is identiÔ¨Åed. This procedure is
applied for both the stability and performance, and the Algorithm 2 terminates when no problematic conÔ¨Åguration is found.
In the implementation, we conducted the worst-case search for performance before that for stability to avoid unnecessary
computations, since performance was observed to fail more frequently than stability. We used the same optimization
parameters as in Section V-C and N = 20, which is deemed sufÔ¨Åcient to ensure thorough validation of the robustness.
2) Results:
As in section V-C, the tests are ran on a 12th Gen Intel(R) Core(TM) i7-12700H 2.30 GHz, with 14 cores and 16GB of
RAM, and computation times are provided for reference. We used the tolerances «´1 = 5% and «´2 = 1% (cf. equation (23)).
The Algorithm 2 was executed 5 times for each strategy. All runs converged to a robust controller. Table I presents a
few averaged metrics for comparison. The runtime of the Ô¨Ånal validation (Step 4) is averaged over all 15 runs, because
this step is conducted identically for each strategy. As the multi-models controller synthesis (Step 1) becomes increasingly
long when the number of active conÔ¨Ågurations increases, Strategy 2 results in the longest runtime. Indeed, although it saves
time by prematurely stopping the PSO, the resulting KKT point is typically not a global optimum, which in turn requires a
larger number of active conÔ¨Ågurations to ensure robustness. Strategy 3, which may add multiple KKT points to the active
conÔ¨Ågurations at each iteration, results in less iterations and a reduced total runtime.
Figure 6 presents the transfer functions of Problem (26) after optimization of the controller. Active conÔ¨Ågurations (in red)
include the worst cases detected in the Ô¨Ånal iteration.
TABLE I: Controller optimization results
Metrics
Strategy 1
Strategy 2
Strategy 3
Nb of iterations ( = nb. of executions of Step 1) (min/avg/max)
7/8.4/10
11/12.2/17
6/7.4/10
Nb. of active conÔ¨Ågurations (min/avg/max)
7/8.6/12
Total runtime, excluding Ô¨Ånal validation (avg)
4034s
4919s
3708s
... including % represented by controller tuning (Step 1)
34%
58%
33%
... including % represented by worst-case searches (Steps 2 and 3)
66%
42%
67%
Runtime of the Ô¨Ånal validation (Step 4 ‚Äì stability) (avg)
139s
Runtime of the Ô¨Ånal validation (Step 4 ‚Äì performance) (avg)
2332s
VI. CONCLUSION
This paper focused on the robust control and worst-case search in presence of nonlinear constraints restricting the
hypercube. This speciÔ¨Åcity is missing from the current state of the art, and arises for example when considering uncertain
mechanical properties e.g. in Ô¨Çexible satellites.
Relying on the theory of upper-C1 functions, we established favorable properties that justify the use of smooth optimization
algorithms for these nonsmooth problems: any subgradient deÔ¨Ånes a valid descent direction, local optima satisfy the
Karush‚ÄìKuhn‚ÄìTucker (KKT) conditions for all subgradients, and sequential quadratic programming converges to KKT points
when applied to such functions. This theoretical foundation legitimizes the use of standard, readily available optimization
tools, which is of practical importance for industrial users.
To perform the worst-case search, we combined Particle Swarm Optimization (or Monte-Carlo sampling, if stochastic
guarantees are desired) for global exploration and Sequential Quadratic Programming for local exploitation. Numerical
experiments on a Ô¨Çexible spacecraft benchmark show that this method signiÔ¨Åcantly outperforms Monte-Carlo sampling
alone, and is able to reliably detect even rare worst-case conÔ¨Ågurations. Then, by iteratively constructing a set of active
conÔ¨Ågurations, multi-objectives robust controller optimization was performed in reasonable runtime.


Frequency (rad/s)
Singular Values (dB)
10-2
10-1
100
101
102
-20
0
20
40
60
Random samples
Active configurations
(a) Tn‚Üíu(s, K‚àó, Œ¥)
Frequency (rad/s)
Singular Values (dB)
10-2
10-1
100
101
102
-50
-40
-30
-20
-10
0
10
Requirement
Random samples
Active configurations
(b) Ts‚Üíu(s, K‚àó, Œ¥)
Frequency (rad/s)
Singular Values (dB)
10-2
10-1
100
101
102
-15
-10
-5
0
5
10
Requirement (W-1)
Random samples
Active configurations
(c) Tr‚Üíe(s, K‚àó, Œ¥)
Fig. 6: Transfer functions in Problem (26) after controller optimization, with active conÔ¨Ågurations and 100 random samples
Finally, we emphasize that the proposed worst-case search, performing global exploration and being compatible with a
large number of uncertain parameters and states, has the potential to complement existing robust control techniques, including
in the unconstrained case.
FUNDING SOURCES
This work was funded par R¬¥egion Occitanie in the frame of the France 2030 program. Ce projet a ¬¥et¬¥e Ô¨Ånanc¬¥e par la
R¬¥egion Occitanie dans le cadre de France 2030.
ACKNOWLEDGMENTS
The authors acknowledge the use of an AI tool (ChatGPT: GPT-4) to assist in the reformulation of certain sentences.
REFERENCES
[1] P. Apkarian and D. Noll, ‚ÄúThe H inÔ¨Ånity Control Problem is Solved,‚Äù Aerospace Lab, no. 13, pp. 1‚Äì27, 2017.
[2] P. Apkarian, M. N. Dao, and D. Noll, ‚ÄúParametric Robust Structured Control Design,‚Äù IEEE Transactions on Automatic Control, vol. 60, no. 7, pp.
1857‚Äì1869, 2015, arXiv: 1405.4202 Publisher: IEEE.
[3] P. Apkarian and D. Noll, ‚ÄúNonsmooth H inÔ¨Ånity synthesis,‚Äù IEEE Transactions on Automatic Control, vol. 51, no. 1, pp. 71‚Äì86, 2006.
[4] F. Clarke, Optimization and nonsmooth analysis, ser. Society for industrial and Applied Mathematics, 1990.
[5] S. Boyd and C. Barratt, Linear Controller Design: Limits of Performance, ser. Englewood Cliffs, NJ: Prentice Hall., 1991.
[6] J. Doyle, ‚ÄúAnalysis of feedback systems with structured uncertainties,‚Äù IEE Proceedings D Control Theory and Applications, vol. 129, no. 6, p.
242, 1982. [Online]. Available: https://digital-library.theiet.org/content/journals/10.1049/ip-d.1982.0053
[7] C. Roos, ‚ÄúSystems modeling, analysis and control (SMAC) toolbox: An insight into the robustness analysis library,‚Äù in 2013 IEEE
Conference on Computer Aided Control System Design (CACSD).
Hyderabad, India: IEEE, Aug. 2013, pp. 176‚Äì181. [Online]. Available:
http://ieeexplore.ieee.org/document/6663479/
[8] J.-M. Biannic, C. Roos, S. Bennani, F. Boquet, V. Preda, and B. Girouart, ‚ÄúAdvanced probabilistic mu -analysis techniques for AOCS validation,‚Äù
European Journal of Control, vol. 62, pp. 120‚Äì129, Nov. 2021. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0947358021000789


[9] F. Somers, C. Roos, J. Biannic, F. Sanfedino, V. Preda, S. Bennani, and H. Evain, ‚ÄúDelay Margin Analysis of Uncertain Linear Control Systems
Using Probabilistic mu,‚Äù International Journal of Robust and Nonlinear Control, vol. 35, no. 6, pp. 2101‚Äì2118, Apr. 2025. [Online]. Available:
https://onlinelibrary.wiley.com/doi/10.1002/rnc.7780
[10] R.
Tempo,
E.
Bai,
and
F.
Dabbene,
‚ÄúProbabilistic
robustness
analysis:
explicit
bounds
for
the
minimum
number
of
samples,‚Äù
in
Proceedings of 35th IEEE Conference on Decision and Control, vol. 3.
Kobe, Japan: IEEE, 1996, pp. 3424‚Äì3428. [Online]. Available:
http://ieeexplore.ieee.org/document/573690/
[11] J. E. Spingarn, ‚ÄúSubmonotone subdifferentials of Lipschitz functions,‚Äù vol. 264, no. 1, 1981.
[12] J. Nocedal and S. J. Wright, Numerical optimization, second edition ed., ser. Springer series in operations research and Ô¨Ånancial engineering.
New
York, NY: Springer, 2006.
[13] J. Kennedy and R. Eberhart, ‚ÄúParticle swarm optimization,‚Äù in Proceedings of ICNN‚Äô95 - International Conference on Neural Networks, vol. 4.
Perth, WA, Australia: IEEE, 1995, pp. 1942‚Äì1948. [Online]. Available: http://ieeexplore.ieee.org/document/488968/
[14] M. Davenport and M. Egerstedt, ‚ÄúConvex optimization - Course notes.‚Äù [Online]. Available: https://mdav.ece.gatech.edu/ece-6270-spring2021/notes/
[15] E. Kassarian, F. Sanfedino, D. Alazard, J. Montel, and C.-A. Chevrier, ‚ÄúModeling of stratospheric balloons and robust line-of-sight pointing control,‚Äù
CEAS Space Journal, Jul. 2023. [Online]. Available: https://link.springer.com/10.1007/s12567-023-00515-x
[16] E. Kassarian, F. Sanfedino, D. Alazard, and H. Evain, ‚ÄúParametric sensitivity analysis for the robust control of uncertain space systems,‚Äù in EuroGNC,
Bristol, 2024.
[17] M. Martin, S. Winkler, F. Belien, and R. Forstner, ‚ÄúTowards new V&V in AOCS/GNC for industrial efÔ¨Åciency,‚Äù in ESA-GNC 2023, 2023.
[18] M. Martin, S. Winkler, F. Belien, and R. F¬®orstner, ‚ÄúSample-based sensitivity analysis for uncertain AOCS veriÔ¨Åcation and validation,‚Äù CEAS Space
Journal, Jul. 2025. [Online]. Available: https://link.springer.com/10.1007/s12567-025-00619-6
[19] F. Sanfedino, P. Iannelli, D. Alazard, and E. Pelletier, ‚ÄúEuropean Satellite Benchmark for Control Education & Industrial Training - Lesson Learned
in the Control Design of a Fine Pointing Mission,‚Äù 2025. [Online]. Available: https://ssrn.com/abstract=5231029
[20] L. Szerdahely, S. Fugger, P. Espeillac, G. Monroig, T. Pareaud, and M. Casasco, ‚ÄúThe BepiColombo attitude and orbit control system,‚Äù in Proceedings
of the 9th ESA-GNC conference, Porto, Portugal, 2014.
[21] A. Falcoz, C. Pittet, S. Bennani, A. Guignard, C. Bayart, and B. Frapard, ‚ÄúSystematic design methods of robust and structured controllers for
satellites: Application to the reÔ¨Ånement of Rosetta‚Äôs orbit controller,‚Äù CEAS Space Journal, vol. 7, no. 3, pp. 319‚Äì334, Sep. 2015. [Online].
Available: http://link.springer.com/10.1007/s12567-015-0099-8
[22] C. Charbonnel, ‚ÄúH?? Controller Design and m-Analysis: Powerful Tools for Flexible Satellite Attitude Control,‚Äù in AIAA Guidance, Navigation,
and Control Conference.
Toronto, Ontario, Canada: American Institute of Aeronautics and Astronautics, Aug. 2010. [Online]. Available:
https://arc.aiaa.org/doi/10.2514/6.2010-7907
[23] M. N. Dao, ‚ÄúBundle Method for Nonconvex Nonsmooth Constrained Optimization,‚Äù Journal of convex analysis, vol. 22, no. 4, pp. 1061‚Äì1090, 2015.
[24] P. Apkarian and D. Noll, ‚ÄúWorst-case stability and performance with mixed parametric and dynamic uncertainties,‚Äù International Journal of Robust
and Nonlinear Control, vol. 27, no. 8, pp. 1284‚Äì1301, May 2017. [Online]. Available: https://onlinelibrary.wiley.com/doi/10.1002/rnc.3628
[25] W. De Oliveira, ‚ÄúShort Paper - A note on the Frank‚ÄìWolfe algorithm for a class of nonconvex and nonsmooth optimization problems,‚Äù Open
Journal of Mathematical Optimization, vol. 4, pp. 1‚Äì10, Jan. 2023. [Online]. Available: https://ojmo.centre-mersenne.org/articles/10.5802/ojmo.21/
[26] S. P. Han, ‚ÄúA globally convergent method for nonlinear programming,‚Äù Journal of Optimization Theory and Applications, vol. 22, pp. 297‚Äì309, 1977.
[27] M.
J.
D.
Powell,
‚ÄúVariable
Metric
Methods
for
Constrained
Optimization,‚Äù
in
Mathematical
Programming
The
State
of
the
Art,
A. Bachem, B. Korte, and M. Gr¬®otschel, Eds.
Berlin, Heidelberg: Springer Berlin Heidelberg, 1983, pp. 288‚Äì311. [Online]. Available:
http://link.springer.com/10.1007/978-3-642-68874-4 12
[28] K. Zhou, J. C. Doyle, and K. Glover, Robust and Optimal Control.
Englewood Cliffs: Prentice hall, 1996, iSSN: 09670661.
[29] T. Rautert and E. W. Sachs, ‚ÄúComputational Design of Optimal Output Feedback Controllers,‚Äù SIAM Journal on Optimization, vol. 7, no. 3, pp.
837‚Äì852, Aug. 1997. [Online]. Available: http://epubs.siam.org/doi/10.1137/S1052623495290441
[30] P. Apkarian, D. Noll, and A. Rondepierre, ‚ÄúMixed H2/HinÔ¨Ånity control via nonsmooth optimization,‚Äù in Proceedings of the 48h IEEE Conference
on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference.
Shanghai, China: IEEE, Dec. 2009, pp. 6460‚Äì6465.
[Online]. Available: http://ieeexplore.ieee.org/document/5400165/
[31] D. Arzelier,
D. Georgia, S. Gumussoy, and D. Henrion, ‚ÄúH2 for HIFOO,‚Äù Oct. 2010, arXiv:1010.1442
[math]. [Online].
Available:
http://arxiv.org/abs/1010.1442
[32] P. Apkarian and D. Noll, ‚ÄúController Design via Nonsmooth Multidirectional Search,‚Äù SIAM Journal on Control and Optimization, vol. 44, no. 6,
pp. 1923‚Äì1949, Jan. 2006. [Online]. Available: http://epubs.siam.org/doi/10.1137/S0363012904441684
[33] J. V. Burke, A. S. Lewis, and M. L. Overton, ‚ÄúA Robust Gradient Sampling Algorithm for Nonsmooth, Nonconvex Optimization,‚Äù SIAM Journal on
Optimization, vol. 15, no. 3, pp. 751‚Äì779, Jan. 2005. [Online]. Available: http://epubs.siam.org/doi/10.1137/030601296
[34] V. Bompart, D. Noll, and P. Apkarian, ‚ÄúSecond-order nonsmooth optimization for H inÔ¨Ånity synthesis,‚Äù Numerische Mathematik, vol. 107, no. 3,
pp. 433‚Äì454, Aug. 2007. [Online]. Available: http://link.springer.com/10.1007/s00211-007-0095-9
[35] M. L. Overton and R. S. Womersley, ‚ÄúOn Minimizing the Special Radius of a Nonsymmetric Matrix Function: Optimality Conditions
and Duality Theory,‚Äù SIAM Journal on Matrix Analysis and Applications, vol. 9, no. 4, pp. 473‚Äì498, Oct. 1988. [Online]. Available:
http://epubs.siam.org/doi/10.1137/0609040
[36] V. Bompart, P. Apkarian, and D. Noll, ‚ÄúNon-smooth techniques for stabilizing linear systems,‚Äù in 2007 American Control Conference.
New York,
NY, USA: IEEE, Jul. 2007, pp. 1245‚Äì1250. [Online]. Available: http://ieeexplore.ieee.org/document/4282408/
[37] J. V. Burke and M. L. Overton, ‚ÄúDifferential
properties
of the spectral abscissa and the spectral radius for analytic
matrix-valued
mappings,‚Äù
Nonlinear
Analysis:
Theory,
Methods
&
Applications,
vol.
23,
no.
4,
pp.
467‚Äì488,
Aug.
1994.
[Online].
Available:
https://linkinghub.elsevier.com/retrieve/pii/0362546X94900906
[38] F. Oustry, ‚ÄúA second-order bundle method to minimize the maximum eigenvalue function,‚Äù Mathematical Programming, vol. 89, no. 1, pp. 1‚Äì33,
Nov. 2000. [Online]. Available: http://link.springer.com/10.1007/PL00011388
[39] D. Noll and P. Apkarian, ‚ÄúSpectral bundle methods for non-convexe maximum eigenvalue functions. Part 1: Ô¨Årst-order methods,‚Äù vol. 104, pp.
701‚Äì727, 2005.
[40] J. V. Burke, A. S. Lewis, and M. L. Overton, ‚ÄúTwo numerical methods for optimizing matrix stability,‚Äù Linear Algebra and its Applications, vol.
351-352, pp. 117‚Äì145, Aug. 2002. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0024379502002604
[41] ‚ÄúConstrained Nonlinear Optimization Algorithms, MATLAB help page,‚Äù 2025. [Online]. Available: https://fr.mathworks.com/help/optim/ug/
constrained-nonlinear-optimization-algorithms.html
[42] ‚ÄúParticle
swarm
optimization
algorithm,
MATLAB
help
page,‚Äù
2025.
[Online].
Available:
https://fr.mathworks.com/help/gads/
particle-swarm-optimization-algorithm.html
[43] P. Apkarian and D. Noll, ‚ÄúNonsmooth optimization for multidisk H inÔ¨Ånity synthesis,‚Äù European Journal of Control, vol. 12, no. 3, pp. 229‚Äì244,
2006.
[44] P. Apkarian, P. Gahinet, and C. Buhr, ‚ÄúMulti-model, multi-objective tuning of Ô¨Åxed-structure controllers,‚Äù in 2014 European Control Conference
(ECC).
Strasbourg, France: IEEE, Jun. 2014, pp. 856‚Äì861. [Online]. Available: http://ieeexplore.ieee.org/document/6862200/


[45] D. Alazard, C. Cumer, and K. Tantawi, ‚ÄúLinear dynamic modeling of spacecraft with various Ô¨Çexible appendages and on-board angular momentums,‚Äù
7th International ESA Conference on Guidance, Navigation and Control Systems, vol. 41, no. 2, pp. 11 148‚Äì11 153, 2008, iSBN: 9783902661005.
[46] D. Alazard and F. Sanfedino, ‚ÄúSatellite Dynamics Toolbox for Preliminary Design Phase,‚Äù 43rd Annual AAS Guidance and Control Conference, vol.
172, pp. 1461‚Äì147, 2020.
[47] F. Sanfedino, D. Alazard, E. Kassarian, and F. Somers, ‚ÄúSatellite Dynamics Toolbox Library: a tool to model multi-body space systems for robust
control synthesis and analysis,‚Äù in IFAC PapersOnline, Mar. 2023.
[48] Q. Li, S.-Y. Liu, and X.-S. Yang, ‚ÄúInÔ¨Çuence of initialization on the performance of metaheuristic optimizers,‚Äù Applied Soft Computing, vol. 91, p.
106193, Jun. 2020. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1568494620301332
[49] A. P. Piotrowski, J. J. Napiorkowski, and A. E. Piotrowska, ‚ÄúPopulation size in Particle Swarm Optimization,‚Äù Swarm and Evolutionary Computation,
vol. 58, p. 100718, Nov. 2020. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S2210650220303710
[50] P. Apkarian, D. Noll, and L. Ravanbod, ‚ÄúNonsmooth Bundle Trust-region Algorithm with Applications to Robust Stability,‚Äù Set-Valued and
Variational Analysis, vol. 24, no. 1, pp. 115‚Äì148, Mar. 2016. [Online]. Available: http://link.springer.com/10.1007/s11228-015-0352-5
[51] J. W. Daniel, ‚ÄúStability of the solution of deÔ¨Ånite quadratic programs,‚Äù Mathematical Programming, vol. 5, no. 1, pp. 41‚Äì53, Dec. 1973. [Online].
Available: http://link.springer.com/10.1007/BF01580110
[52] F. Clarke, Y. Ledyaev, R. Stern, and P. Wolenski, Nonsmooth analysis and control theory.
Springer New York.
APPENDIX
In this Appendix, we prove the propositions of Section II. For readability, they are reminded before introducing the proofs.
Proposition 1 (Descent directions and optimality of upper-C1 functions ‚Äì Unconstrained case)
Let a locally Lipschitz function f be upper-C1 at x, and gx ‚àà‚àÇf(x) any subgradient of f at x. We consider Problem (6).
a) Descent direction. Any direction ‚àígx, with gx ‚àà‚àÇf(x) such that ||gx|| Ã∏= 0, is a descent direction for f(x), and in
particular it veriÔ¨Åes f ‚Ä≤(x, ‚àígx) ‚â§‚àí||gx||2 < 0 where f ‚Ä≤(x, d) denotes the the directional derivative at x in direction d.
b) Optimality. If x (locally) minimizes f(x), then ||gx|| = 0 for any gx ‚àà‚àÇf(x).
Proof. The proof is provided in the body of the paper.
Proposition 2 (Descent directions and optimality of upper-C1 functions ‚Äì Constrained case)
Let a locally Lipschitz function f be upper-C1 at x, and gx ‚àà‚àÇf(x) any subgradient of f at x. Let the ci be continuously
differentiable. We consider Problem (8).
a) Descent direction. Let (p, u) be a KKT pair of Q(x, H, gx). If ||p|| Ã∏= 0 and ||u||‚àû‚â§r, then p is a descent direction
for Œ∏r(x), i.e. Œ∏‚Ä≤
r(x, p) < 0 where Œ∏‚Ä≤
r(x, d) denotes the the directional derivative at x in direction d.
b) Optimality. If x (locally) minimizes f(x) subject to n constraints ci(x) ‚â§0 (Problem (8)), then any gx ‚àà‚àÇf(x) veriÔ¨Åes
the following KKT conditions: there exists (¬µi)1‚â§i‚â§n such that:
gx + Pn
i=1 ¬µi‚àáci(x) = 0
‚àÄi, ¬µi ‚â•0, ¬µici(x) = 0, ci(x) ‚â§0
Proof. a) The proof of a) is an adaptation of [26, Theorem 3.1], originally written for a differentiable f, to the upper-C1
case. Let us deÔ¨Åne:
I = {i : ci(x) > 0}, ¬ØI = {i : ci(x) = 0},; ÀÜI = {i : ci(x) < 0}
As in [26] we have:
Œ∏‚Ä≤
r(x, p) = f ‚Ä≤(x, p) + r
X
i‚ààI
‚àáci(x)T p + r
X
i‚àà¬ØI
(‚àáci(x)T p)+ .
Since f is upper-C1, we have f ‚Ä≤(x, p) = ming‚àà‚àÇf(x)‚ü®g, p‚ü©‚â§gT
x p and thus
Œ∏‚Ä≤
r(x, p) ‚â§gT
x p + r
X
i‚ààI
‚àáci(x)T p + r
X
i‚àà¬ØI
(‚àáci(x)T p)+ .
In the original proof of [26, Theorem 3.1], the expression above is an equality with ‚àáf(x) instead of gx. From there, the
proof of [26, Theorem 3.1] is identical, as follows. Since (p, u) is a KKT pair of Q(x, H, gx), we have ci(x)+‚àáci(x)T p ‚â§0
which yields:
X
i‚àà¬ØI
(‚àáci(x)T p)+ = 0
and since ui(ci(x) + ‚àáci(x)T p) = 0, we deduce:
Œ∏‚Ä≤
r(x, p) ‚â§gT
x p +
n
X
i=1
ui‚àáci(x)T p +
n
X
i=1
uici(x) + r
X
i‚ààI
‚àáci(x)T p .


Since (p, u) is a KKT pair of Q(x, H, gx) we also have:
gx +
n
X
i=1
ui‚àáci(x) + 1
2(H + HT )p = 0
and noticing that Pn
i‚àà¬ØI‚à™ÀÜI uici(x) ‚â§0 yields:
Œ∏‚Ä≤
r(x, p) ‚â§‚àí1
2(H + HT )p +
n
X
i‚ààI
(ci(x) + r‚àáci(x)T p)
‚â§‚àí1
2(H + HT )p +
n
X
i‚ààI
(ui ‚àír)ci(x)
< 0
since H is positive deÔ¨Ånite and |u|‚àû< r.
b) is proved in the body of the paper.
To prove Proposition 3, we Ô¨Årst introduce the following lemmas.
Lemma 1 (Submonotonicity) Let f be upper-C1 at x. For every «´ > 0, there exists Œ¥ > 0 such that for all x0, x‚Ä≤
0 ‚ààB(x, Œ¥):
(gx‚Ä≤
0 ‚àígx0)T (x‚Ä≤
0 ‚àíx0) ‚â§«´||x‚Ä≤
0 ‚àíx0||
where gx0 ‚àà‚àÇf(x0) and gx‚Ä≤
0 ‚àà‚àÇf(x‚Ä≤
0).
Proof. This comes from [11, Theorem 3.9] and is also noted for example in [50, Lemma 6].
Lemma 2 (Perturbation of a quadratic problem) Let us consider the two quadratic problems:
x0 = arg min

Q(x) = 1
2xT Kx ‚àíxT k , subject to Gx ‚â§g

x‚Ä≤
0 = arg min

Q‚Ä≤(x) = 1
2xT K‚Ä≤x ‚àíxT k‚Ä≤ , subject to G‚Ä≤x ‚â§g‚Ä≤

where K, K‚Ä≤ are symmetric, positive deÔ¨Ånite matrices. Let us partition G in matrices A, B and g in vectors a, b such that
Bx ‚â§b is always satisÔ¨Åed as an equality while Ax ‚â§a can be satisÔ¨Åed with strict inequality. Let us deÔ¨Åne similarly B‚Ä≤ in
the partition of G‚Ä≤ and suppose that rank(B) = rank(B‚Ä≤). Set «´ = max

||K ‚àíK‚Ä≤||, ||G ‚àíG‚Ä≤||, ||g ‚àíg‚Ä≤||, (k‚Ä≤‚àík)T (x‚Ä≤
0‚àíx0)
||x‚Ä≤
0‚àíx0||

.
Then there exists «´0 > 0 and c > 0 such that:
||x‚Ä≤
0 ‚àíx0|| ‚â§c«´
whenever «´ < «´0.
Proof. This lemma is an adaptation of [51] where, instead of our assumption (k‚Ä≤ ‚àík)T (x‚Ä≤
0 ‚àíx0) ‚â§«´||x‚Ä≤
0 ‚àíx0||, the stronger
assumption ||k‚Ä≤ ‚àík|| ‚â§«´ was considered. Let us note Œª > 0 the smallest eigenvalue of K. Let us Ô¨Årst demonstrate the
equivalent of [51, Theorem 2.1], i.e., that in the unconstrained case:
x0 = arg min

Q(x) = 1
2xT Kx ‚àíxT k

,
x‚Ä≤
0 = arg min

Q‚Ä≤(x)1
2xT K‚Ä≤x ‚àíxT k‚Ä≤

we have:
||x‚Ä≤
0 ‚àíx0|| ‚â§«´(Œª ‚àí«´)‚àí1(1 + ||x0||) .
The proof for this statement is almost identical to the one provided in [51, Theorem 2.1], as follows. For any x ‚ààRk, we
have:
(x ‚àíx0)T ‚àáQ(x0) ‚â•0
(x ‚àíx‚Ä≤
0)T ‚àáQ‚Ä≤(x‚Ä≤
0) ‚â•0


with the gradients ‚àáQ(x) = Kx ‚àík and ‚àáQ(x) = K‚Ä≤x ‚àík‚Ä≤. Substituting x = x‚Ä≤
0 and x = x0 respectively in these two
equations and adding the results yields
(x‚Ä≤
0 ‚àíx0)T (‚àáQ(x0) ‚àí‚àáQ‚Ä≤(x‚Ä≤
0)) ‚â•0
which is equivalent to
(x‚Ä≤
0 ‚àíx0)T (‚àáQ‚Ä≤(x‚Ä≤
0) ‚àí‚àáQ‚Ä≤(x0)) ‚â§(x‚Ä≤
0 ‚àíx0)T (‚àáQ(x0) ‚àí‚àáQ‚Ä≤(x0))
For the left side:
(x‚Ä≤
0 ‚àíx0)T (‚àáQ‚Ä≤(x‚Ä≤
0) ‚àí‚àáQ‚Ä≤(x0)) = (x‚Ä≤
0 ‚àíx0)T K‚Ä≤(x‚Ä≤
0 ‚àíx0)
‚â•(Œª ‚àí«´)||x‚Ä≤
0 ‚àíx0||2
For the right side:
(x‚Ä≤
0 ‚àíx0)T (‚àáQ(x0) ‚àí‚àáQ‚Ä≤(x0)) = (x‚Ä≤
0 ‚àíx0)T (K ‚àíK‚Ä≤)x0 + (x‚Ä≤
0 ‚àíx0)T (k‚Ä≤ ‚àík)
‚â§«´||x‚Ä≤
0 ‚àíx0||(||x0|| + 1)
which Ô¨Ånalizes the proof for the unconstrained case. Note that the only difference with the original proof of [51, Theorem
2.1] is that they used (x‚Ä≤
0 ‚àíx0)T (k‚Ä≤ ‚àík) ‚â§||x‚Ä≤
0 ‚àíx0|| ¬∑ ||k‚Ä≤ ‚àík|| to deduce (x‚Ä≤
0 ‚àíx0)T (k‚Ä≤ ‚àík) ‚â§«´||x‚Ä≤
0 ‚àíx0||, whereas it
was directly our assumption.
Then, the rest of the proof provided in [51] still holds. Indeed, the propositions [51, Propositions 3.1, 3.2] only tackle the
constrained sets, and do not involve k or k‚Ä≤. Moreover, in, [51, Section 4], the relationship between k and k‚Ä≤ is not used
(except when using [51, Theorem 2.1], which we generalized already); in fact, [51, Section 4] only works on Q(x).
Proposition 3 (Convergence of SQP for upper-C1 functions)
Let f be upper-C1 and the ci be continuously differentiable. Assume that the following conditions are satisÔ¨Åed:
(i) there exists Œ±, Œ≤ > 0 such that, for each k and for any x ‚ààRk:
Œ±xT x ‚â§xT Hkx ‚â§Œ≤xT x
(ii) For each k, there exists a KKT point of Q(xk, Hk, gxk) (equation (10)) with a Lagrange multiplier vector uk such
that ||uk||‚àû‚â§r.
Then, any sequence (xk) generated by Algorithm 1 either terminates at a KKT point of the constrained optimization
problem (8), or any accumulation point ¬Øx with
S0(¬Øx) = {p : c(¬Øx) + ‚àác(¬Øx)T p < 0} Ã∏= ‚àÖ
is a KKT point of Problem (8).
Proof. Once again, we follow the proof of [26, Theorem 3.2] and adapt it to the case where f is not differentiable but
only upper-C1. For completeness, we reproduce the entire proof and indicate where our modiÔ¨Åed assumptions apply, while
emphasizing that the proof itself is not our own.
By assumption (ii), (pk, uk) is a KKT pair of Q(xk, Hk, gxk) with ||uk||‚àû‚â§r. If pk = 0, then (xk, uk) satisÔ¨Åes the
KKT conditions (9) of Problem (8) and the algorithm can terminate at xk.
Thus, for the following, we assume that pk Ã∏= 0. From Proposition 2.a) (originally [26, Theorem 3.1], which we adapted
to upper-C1 functions), it is possible to choose xk+1 as described in Algorithm 1, and in particular, it veriÔ¨Åes:
Œ∏r(xk+1) < Œ∏r(xk) + «´k .
Let ¬Øx be an accumulation point of (xk) with S0(¬Øx) Ã∏= ‚àÖ. Without loss of generality (passing to the subsequence if necessary)
we may assume
xk ‚Üí¬Øx , Hk ‚Üí¬ØH
where the existence of ¬ØH follows from assumption (i).
In the original proof [26], the continuity of the gradient of f ensures that ‚àáf(xk) converges to ‚àáf(¬Øx). Here, a similar
property is maintained as follows. Since f is locally Lipschitz, its subgradients (gxk) are uniformly bounded for k sufÔ¨Åciently
large, hence there exists a subsequence that converges to a vector ¬Øg. Without loss of generality (passing to the subsequence
if necessary) we note
gxk ‚Üí¬Øg ,
and the upper semi-continuity of the Clarke subdifferential [52, Proposition 1.5] yields ¬Øg ‚àà‚àÇf(¬Øx). Since ¬ØH is positive
deÔ¨Ånite and S0(¬Øx) Ã∏= ‚àÖ, the quadratic problem Q(¬Øx, ¬ØH, ¬Øg) (originally Q(¬Øx, ¬ØH, ‚àáf(¬Øx)) in [26]) has a unique KKT point ¬Øp.


If ¬Øp = 0, then ¬Øx is a KKT point of Problem (8) and the theorem follows. Thus, we now assume that ¬Øp Ã∏= 0 and we will
show that this leads to a contradiction.
From the continuity of ‚àág(x), and by Lemmas 1 and 2, where xk+1 and xk play the roles of x0 and x‚Ä≤
0, and gx0 and
gx‚Ä≤
0 play the roles of k and k‚Ä≤, we deduce that:
pk ‚Üí¬Øp
In the original proof [26], this follows [51] (the equivalent to our Lemma 2) and the continuity of ‚àáf(x) instead (which is
stronger than our Lemma 1).
Since (uk) is uniformly bounded by r, it has an accumulation point ¬Øu. We note
uk ‚Üí¬Øu
with ||¬Øu||‚àû‚â§r. By passing to the limit in the KKT relation, which is valid for any k, we obtain that ¬Øu is a Lagrange
multiplier of Q(¬Øx, ¬ØH, ¬Øg).
The rest of the proof of [26] is unchanged, and is as follows. Let ¬ØŒª ‚àà
0
Œªmax

be chosen such that
Œ∏r(¬Øx + ¬ØŒª¬Øp) =
min
0‚â§Œª‚â§Œªmax Œ∏r(¬Øx + Œª¬Øp).
Let us set
Œ≥ = Œ∏r(¬Øx + ¬ØŒª¬Øp) ‚àíŒ∏r(¬Øx) > 0
which is strictly positive by Proposition 2.a). Since xk + ¬ØŒªpk ‚Üí¬Øx + ¬ØŒª¬Øp, for sufÔ¨Åciently large k we have:
Œ∏r(xk + ¬ØŒªpk) + Œ≥/2 < Œ∏r(¬Øx) .
However, for all k we have Œ∏r(xk+1) < Œ∏r(xk) + «´k, and for sufÔ¨Åciently large k we have
‚àû
X
i=k
«´i < Œ≥/2
which leads to:
Œ∏r(¬Øx) < Œ∏r(xk+1 +
‚àû
X
i=k+1
«´i
‚â§
min
0‚â§Œª‚â§Œªmax Œ∏r(xk + Œªpk) + «´k +
‚àû
X
i=k+1
«´i
< Œ∏r(xk + ¬ØŒªpk) + Œ≥/2
which contradicts the previous inequality Œ∏r(xk + ¬ØŒªpk) + Œ≥/2 < Œ∏r(¬Øx). This proves that ¬Øp = 0 and that ¬Øx is a KKT point
of Problem (8).
